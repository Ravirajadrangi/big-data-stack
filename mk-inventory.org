#+TITLE: mk-inventory
#+AUTHOR: Badi Abdul-Wahid
#+EMAIL: abdulwahidc@gmail.com
#+MACRO: this-file  mk-inventory.org
#+MACRO: project-name: Big-Data-Stack
#+PROPERTY: header-args :tangle mk-inventory :comments both

* About

This is a literate python script written in Emacs Org-Mode.  If making
changes, make sure to edit {{{this-file}}}, not the tangled
(generated) file.

To update the code, open {{{this-file}}} in Emacs (with Org-Mode
installed) and execute =C-c C-v t=


* Purpose

Given the name of a virtual cluster and associated IP addresses,
generate an ansible inventory that works with {{{project-name}}}, and
any associated =host_vars= or =group_vars= file.


* Requirements

In order to run this code you need:

- Python 2.7
- a name of a virtual cluster (alphanumeric with underscores or dashes)
- IP addresses that you can successfully SSH into
- the nodes of the virtual cluster must have Python 2.7 installed


* Imports

We are using the =argparse= module that comes with Python.  While
others argument parsing libraries exists such as =docopts=, =argparse=
is easy to use and (importantly) adds to extra dependencies.

#+BEGIN_SRC python
import argparse
#+END_SRC

We also need the =defaultdict= from the =collections= module.
#+BEGIN_SRC python
from collections import defaultdict
#+END_SRC

We'll also be generating some strings so we'll use =StringIO= to do so effeciently.

#+BEGIN_SRC python
from StringIO import StringIO
#+END_SRC

We'll also need to be reading and writing yaml files, so we should import:

#+BEGIN_SRC python
import yaml
#+END_SRC

We also will be interfacing with the operating system and dealing with
file paths, so we need these modules

#+BEGIN_SRC python
import os
import os.path
#+END_SRC

We will be using =itertools= (namely =cycle=) when assigning nodes to groups

#+BEGIN_SRC python
import itertools
#+END_SRC

* Logging

We'll use the standard built-in =logging= module with a default level of INFO.

#+BEGIN_SRC python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
#+END_SRC

* Getting User Options

This is a convenient description of this program that will be shown to users.

#+BEGIN_SRC python
_DESCRIPTION = """
Generate a valid Ansible inventory file and associated host_vars and group_vars.
You need to provide a name for the virtual cluster, and SSH-able IP addresses.
"""
#+END_SRC

#+BEGIN_SRC python
def get_opts():
    p = argparse.ArgumentParser(
        description=_DESCRIPTION,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    p.add_argument('-n', '--name', metavar='TEXT', default='myvc',
                   help='The name for the virtual cluster')
    p.add_argument('addresses', nargs='+', metavar='IP',
                   help='IP addresses of the cluster')

    return p.parse_args()
#+END_SRC


* Classes

** Node

The =Node= represents everything that is known about a node: namely, name and IP address

#+BEGIN_SRC python
class Node(object):

    def __init__(self, name, address):
        self._name = name
        self._address = address
        self._variables = dict()
#+END_SRC


We also need to add variables to a node

#+BEGIN_SRC python
    def add_var(self, key, value):
        """Add a variable and value to a node. This will show up in the host_vars file

        :param key: the name of the variable
        :type key: :class:`str`
        :param value: the value of the variable
        :type value: anything that is valid YAML
        """

        if key in self._variables:
            logger.warning('Overwriting previous definition of',
                           key, '=', self._variables[key])

        self._variables[key] = value
#+END_SRC


Since a =Node= is immutable we provide properties to access it attributes.

#+BEGIN_SRC python
    @property
    def name(self):
        """The name of this node
        :rtype: :class:`str`
        """
        return self._name


    @property
    def address(self):
        """The IP address of this node
        :rtype: :class:`str`
        """
        return self._address
#+END_SRC

Any properties of the =Node= should be saves as =host_vars=.

#+BEGIN_SRC python
    def as_host_vars(self):
        """generate the ``host_vars`` representation of this node

        :rtype: :class:`str`
        """

        d = dict(
            ansible_ssh_host=self.address
        )
        
        yaml.dump(d, default_flow_style=True)
#+END_SRC



** Inventory

The =Inventory= class trackes all the components of an inventory file:
namely the name of a group and the nodes associated to a group.

#+BEGIN_SRC python
class Inventory(object):

    def __init__(self, groups=None):
        self._groups = groups or defaultdict(set)
        self._nodes = set()


    def add_node(self, group, node):
        """Adds a node to a group

        :param group: the group name (creates if not already present)
        :type group: :class:`str`
        :param node: the node to be inserted in ``group``
        :param node: :class:`Node`
        """

        self._groups[group].add(node)
        self._nodes.add(node)


    def add_group_to(self, src, target):
        """Adds all the nodes in ``src`` to ``target``
        """

        for node in self._groups[src]:
            self.add_node(target, node)


    def as_ini(self):
        """Generates the ansible inventory file in ini text file format (the usual)
        
        :returns: the inventory as usable by Ansible
        :rtype: :class:`str`
        """

        s = StringIO()
        for name, nodes in self._groups:
            s.write('[{}]\n'.format(name))
            for n in node:
                s.write('{}\n'.format(n.name))
                s.write('\n')

        v = s.getvalue()
        s.close()
        return v


    def write_host_vars(self, prefix='.'):
        """Write the host_vars for each node in the inventory.

        :param prefix: where the ``host_vars`` will be written (default is current directory)
        """

        funcs = [os.path.abspath,
                 os.path.expanduser,
                 os.path.expandvars]

        real_prefix = reduce(lambda path, f: f(path),
                             reversed(funcs))

        host_vars = os.path.join(real_prefix, 'host_vars')

        if os.path.exists(host_vars) and not os.path.isdir(path):
            msg = '{} exists and is not a directory'.format(host_vars)
            logger.critical(msg)
            raise ValueError(msg)

        if not os.path.exists(host_vars):
            logger.warning('Creating directory', host_vars)

        logger.info('Writing host_vars to', host_vars)
        for node in self._nodes:
            path = os.path.join(host_vars, '{}.yml'.format(node.name))
            yml  = node.as_host_vars()
            logger.info('Writing', path)
            logger.debug('Writing to', path, yml)

            if os.path.exists(path):
                logger.warning('Overwriting', path)

            with open(path, 'w') as fd:
                fd.write(yml)
#+END_SRC


* Creating =Node=\ s

Nodes are named in sequential order.

#+BEGIN_SRC python
def mk_nodes(vcname, addresses):
    """Creates the :class:`Node`s

    :param vcname: name of the virtual cluster
    :type vcname: :class:`str`
    :param addresses: the ip addresses of the nodes
    :type addresses: :class:`list` of :class:`str`
    :returns: the Nodes
    :rtype: :class:`list` of :class:`Node`
    """

    nodes = list()
    for i, address in enumerate(addresses):
        name = '{name}{i}'.format(name=vcname, i=i)
        n = Node(name, address)
        nodes.append(n)

    return nodes
#+END_SRC


* Groups

There are several important groups that {{{project-name}}} uses:

- zookeeper: the zookeeper nodes
- namenodes: the nodes on which the HDFS namenodes (primary and backup) run
- journalnodes: the nodes on which the HDFS journalnodes run
- historyservers: the nodes on which the history server runs
- resourcemanagers: the nodes on which the YARN resourcemanagers run
- datanodes: the nodes which are used as compute nodes
- frontends: nodes on which users should log into
- hadoopnodes: a metagroup consisting of all nodes running hadoop, yarn, or other analytics software
- monitor: the nodes on which the  monitoring software (eg Ganglia) is installed


** Requirements

There are currently requirements on the number of nodes in each group.
Additionally, as parameterizing these assignments is not currently
supported, we'll just hardcode them here.

The one that is intended to scale dynamically right now is the number
of compute nodes, so you'll notice the absence of =_N_DATANODES= below.

#+BEGIN_SRC python
_N_ZOOKEEPERS = 3
_N_NAMENODES = 2
_N_JOURNALNODES = 3
_N_HISTORYSERVERS = 1
_N_RESOURCEMANAGERS = 2
_N_FRONTENDS = 1
_N_MONITORS = 1
#+END_SRC


* Creating the Inventory

Since the nodes is the virtual cluster are assumed to be identical the
partitioning is arbitrary. We choose to iterate over the available nodes
assigning each to the required group in a semi-round-robin fashion.



#+BEGIN_SRC python
def create_inventory(nodes):
    """Assign the nodes to various groups and return the inventory

    :param nodes: the nodes
    :type nodes: :class:`list` of :class:`Node`
    :returns: the inventory
    :rtype: :class:`Inventory`
    """

    inventory = Inventory()
    inf_nodes = itertools.cycle(nodes)

    for i in xrange(_N_ZOOKEEPERS):
        node = inf_nodes.next()
        node.add_var('zookeeper_id', i)
        inventory.add_node('zookeepernodes', node)

    for _ in xrange(_N_NAMENODES):
        node = inf_nodes.next()
        inventory.add_node('namenodes', node)
    inventory.add_group_to('namenodes', 'hadoopnodes')

    for _ in xrange(_N_JOURNALNODES):
        node = inf_nodes.next()
        inventory.add_node('journalnodes', node)
    inventory.add_group_to('journalnodes', 'hadoopnodes')

    for _ in xrange(_N_HISTORYSERVERS):
        node = inf_nodes.next()
        inventory.add_node('historyservernodes', node)
    inventory.add_group_to('historyservernodes', 'hadoopnodes')

    for _ in xrange(_N_RESOURCEMANAGERS):
        node = inf_nodes.next()
        inventory.add_node('resourcemanagernodes', node)
    inventory.add_group_to('resourcemanagernodes', 'hadoopnodes')

    for _ in xrange(_N_FRONTENDS):
        node = inf_nodes.next()
        inventory.add_node('frontendnodes', node)


    for node in nodes:
        inventory.add_node('datanodes', node)
#+END_SRC

* Entry Points

#+BEGIN_SRC python
def main():
    opts = get_opts()
    print opts
    nodes = mk_nodes(opts.name, opts.addresses)
    inventory = create_inventory(nodes)

if __name__ == '__main__':
    main()
#+END_SRC
